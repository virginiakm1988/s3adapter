adapter:
  exist: true
  type: ['skip', 'seq', 'para', 'lora', 'lnfit', 'bitfit']
  switch: 
    first: false
    exist: true
    # hard: True
    path: [0, 1, 2, 3, 4, 5]
    tau:
      type: linear
      init_value: 5
      stop_value: 0.5
    strategy: global
    ratio: 0.5
    # freq: 0.1  # 0~1
    baseline: -1
    fix_thres: 0.8
    # soft_adapter: False
    algo: 
      name: gdas          # choose from ['gdas', 'darts', 'fair_darts', 's3delta', 'gumbel_darts']
      soft_train: False   # Set to True if you don't want to use one-hot when training weight
      soft_switch: False  # Set to True if you don't want to use one-hot when training switch
      use_gumbel: True    # Set this to True if using sampling-related algorithm, which includes ['s3delta', 'gdas', 'gumbel_darts']
      # For DARTS-based algorithm
      first_order_approx: False
      # For Fair-DARTS
      aux_loss_ratio: 10  # Scaling factor to zero-one loss
      # For S3Delta
      shift_tau: 1

  houlsby:
    input: false

# 0: seq adp, 1: no adp, 2: para adp
